{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stroz Friedberg Lateral Movement Triage\n",
    "\n",
    "### A triage review of Lateral Movement activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Standard imports and variable definitions\n",
    "\n",
    "import pandas\n",
    "import os\n",
    "from pyvelociraptor import velo_pandas\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Import API config file\n",
    "os.environ['VELOCIRAPTOR_API_FILE'] = \"path/to/api.config.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stroz Friedberg Lateral Movement Hunt Jobs\n",
    "\n",
    "### The information is gathered from Stroz Friedberg's Custom.Windows.LateralMovement hunt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Define the Lateral Movement hunt\n",
    "targetArtifact = \"Custom.Windows.LateralMovement\"\n",
    "\n",
    "# Store hunt IDs\n",
    "HUNT_IDS = pandas.DataFrame(velo_pandas.DataFrameQuery(\"\"\"\n",
    "    SELECT hunt_id FROM hunts() WHERE artifacts =~ targetArtifact\n",
    "\"\"\", targetArtifact=targetArtifact))\n",
    "\n",
    "HUNT_IDS.set_index('hunt_id', inplace=True)\n",
    "HUNT_IDS = HUNT_IDS.index.values.tolist()\n",
    "\n",
    "# Read out hunt task summary\n",
    "pandas.DataFrame(velo_pandas.DataFrameQuery(\"\"\"\n",
    "    SELECT hunt_id,hunt_description,timestamp(epoch=start_time) as start_time, stats.total_clients_scheduled as scheduled_clients, stats.total_clients_with_results as systems_with_results FROM hunts() WHERE artifacts =~ targetArtifact\n",
    "\"\"\", targetArtifact=targetArtifact))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Lateral Movement hunt results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remote-input",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Loop through applicable hunts pull down data\n",
    "huntResults = []\n",
    "ArtifactHuntPairs = []\n",
    "\n",
    "print(HUNT_IDS)\n",
    "\n",
    "for i in HUNT_IDS:\n",
    "    query = pandas.DataFrame(velo_pandas.DataFrameQuery(\"\"\"\n",
    "        SELECT * FROM flatten(query={SELECT hunt_info(hunt_id=HuntId).artifact_sources AS sourcetopull\n",
    "                                      FROM scope()})\n",
    "    \"\"\", HuntId=i, timeout=9999999))\n",
    "    query.set_index('sourcetopull', inplace=True)\n",
    "    query = query.index.values.tolist()\n",
    "    ArtifactHuntPairs.append([i, query])\n",
    "print(ArtifactHuntPairs)\n",
    "\n",
    "for i in ArtifactHuntPairs:\n",
    "    for j in i[1]:\n",
    "        query = pandas.DataFrame(velo_pandas.DataFrameQuery(\"\"\"\n",
    "            SELECT *\n",
    "            FROM hunt_results(hunt_id=HuntId, artifact=artifact)\n",
    "        \"\"\", HuntId=i[0], artifact=j, timeout=999999))\n",
    "        huntResults.append(query)\n",
    "        print(query)\n",
    "\n",
    "huntResults = pandas.concat(huntResults)\n",
    "\n",
    "print(huntResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lateral Movement Connection Statistics\n",
    "\n",
    "Outgoing Lateral Movement connection information collected to better understand typical Lateral Movement behavior in the environment, and highlight potential outliers for additional review.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lateral Movement Top Originators\n",
    "\n",
    "Systems which detailed larger than normal outgoing LM connections in the environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huntResults.loc[huntResults['SourceSystem'] != \"-\"].value_counts(subset=['SourceSystem'], sort=True ).nlargest(25).to_frame(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outgoing Lateral Movement Top Talker Accounts\n",
    "\n",
    "Accounts attempting initiating the largest count of interactive Lateral Movement sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huntResults.value_counts(subset=['UserAccount'], sort=True, ).nlargest(25).to_frame(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Lateral MovementTalkers Over Time\n",
    "\n",
    "Visualizes top account usage over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huntResults_fixed = huntResults.copy()\n",
    "\n",
    "# Convert EventTime to datetime if needed\n",
    "if not pandas.api.types.is_datetime64_any_dtype(huntResults_fixed['EventTime']):\n",
    "    try:\n",
    "        # Try Unix timestamp first\n",
    "        huntResults_fixed['EventTime'] = pandas.to_datetime(huntResults_fixed['EventTime'], unit='s', errors='ignore')\n",
    "        if not pandas.api.types.is_datetime64_any_dtype(huntResults_fixed['EventTime']):\n",
    "            # Try string parsing\n",
    "            huntResults_fixed['EventTime'] = pandas.to_datetime(huntResults_fixed['EventTime'], errors='coerce')\n",
    "    except:\n",
    "        huntResults_fixed['EventTime'] = pandas.to_datetime(huntResults_fixed['EventTime'], errors='coerce')\n",
    "\n",
    "# Remove invalid datetime entries\n",
    "huntResults_fixed = huntResults_fixed.dropna(subset=['EventTime'])\n",
    "\n",
    "# Remove invalid datetime entries\n",
    "huntResults_fixed = huntResults_fixed.dropna(subset=['EventTime'])\n",
    "talkerData = pandas.DataFrame({\n",
    "    'Date' : huntResults_fixed['EventTime'].dt.strftime('%Y-%m-%d'),\n",
    "    'User' : huntResults_fixed['UserAccount']\n",
    "})\n",
    "\n",
    "# Add a Count column \n",
    "results = talkerData.groupby([talkerData['Date'], talkerData['User']]).size().to_frame('count').reset_index()\n",
    "\n",
    "# Figure out the average\n",
    "mean = results['count'].mean()\n",
    "top = results['count'].quantile(0.98)\n",
    "\n",
    "# Create dataset that ONLY returns login counts ABOVE the typical average\n",
    "resultsMean = results[results['count'] > mean]\n",
    "\n",
    "# Create scatter plot \n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(resultsMean['Date'], resultsMean['count'])\n",
    "\n",
    "# Annotate only the top percent entered above in \"top\" variable\n",
    "for k, v in resultsMean.iterrows():\n",
    "    if (v['count'] > top):\n",
    "        ax.annotate(v['User'], xy=(v['Date'] ,v['count']))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the accounts highlighted above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['count'] > top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lateral Movement Outgoing Pivots\n",
    "\n",
    "Details system connections and their relationships to potentially identify pivot points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show, save\n",
    "from bokeh.models import Range1d, Circle, ColumnDataSource, MultiLine, LabelSet\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.plotting import from_networkx\n",
    "from bokeh.palettes import Blues8, Reds8, Purples8, Oranges8, Viridis8, Spectral8\n",
    "from bokeh.transform import linear_cmap\n",
    "\n",
    "output_notebook(hide_banner=True)\n",
    "network_df = pandas.DataFrame({\n",
    "    'SourceSystem' : huntResults['SourceSystem'],\n",
    "    'DestinationSystem' : huntResults['DestinationSystem'],\n",
    "})\n",
    "\n",
    "# Add a Count column \n",
    "network_df = network_df.groupby([network_df['SourceSystem'], network_df['DestinationSystem']]).size().to_frame('Weight').reset_index()\n",
    "\n",
    "# Throw out logs with no destinations\n",
    "network_df = network_df[network_df.DestinationSystem != '-']\n",
    "network_df = network_df[network_df.SourceSystem != '-']\n",
    "\n",
    "G = nx.from_pandas_edgelist(network_df, 'SourceSystem', 'DestinationSystem', True)\n",
    "G.edges(data=True)\n",
    "\n",
    "degrees = dict(nx.degree(G))\n",
    "nx.set_node_attributes(G, name='degree', values=degrees)\n",
    "\n",
    "number_to_adjust_by = 5\n",
    "adjusted_node_size = dict([(node, degree+number_to_adjust_by) for node, degree in nx.degree(G)])\n",
    "nx.set_node_attributes(G, name='adjusted_node_size', values=adjusted_node_size)\n",
    "\n",
    "#Choose attributes from G network to size and color by — setting manual size (e.g. 10) or color (e.g. 'skyblue') also allowed\n",
    "size_by_this_attribute = 'adjusted_node_size'\n",
    "color_by_this_attribute = 'adjusted_node_size'\n",
    "\n",
    "#Pick a color palette — Blues8, Reds8, Purples8, Oranges8, Viridis8\n",
    "color_palette = Blues8\n",
    "\n",
    "title = 'LM Outgoing Connections'\n",
    "\n",
    "#Establish which categories will appear when hovering over each node\n",
    "HOVER_TOOLTIPS = [\n",
    "       (\"Source\", \"@index\"),\n",
    "        (\"Degree\", \"@degree\")\n",
    "]\n",
    "\n",
    "#Create a plot — set dimensions, toolbar, and title\n",
    "plot = figure(tooltips = HOVER_TOOLTIPS,\n",
    "              tools=\"pan,wheel_zoom,save,reset\", active_scroll='wheel_zoom',\n",
    "            x_range=Range1d(-10.1, 10.1), y_range=Range1d(-10.1, 10.1), title=title)\n",
    "\n",
    "plot.sizing_mode = \"scale_width\"\n",
    "#Create a network graph object with spring layout\n",
    "# https://networkx.github.io/documentation/networkx-1.9/reference/generated/networkx.drawing.layout.spring_layout.html\n",
    "network_graph = from_networkx(G, nx.spring_layout, scale=10, center=(0, 0))\n",
    "\n",
    "#Set node sizes and colors according to node degree (color as spectrum of color palette)\n",
    "minimum_value_color = min(network_graph.node_renderer.data_source.data[color_by_this_attribute])\n",
    "maximum_value_color = max(network_graph.node_renderer.data_source.data[color_by_this_attribute])\n",
    "network_graph.node_renderer.glyph = Circle(radius=0.5,fill_color=linear_cmap(color_by_this_attribute, color_palette, minimum_value_color, maximum_value_color))\n",
    "\n",
    "#Set edge opacity and width\n",
    "network_graph.edge_renderer.glyph = MultiLine(line_alpha=0.5, line_width=1)\n",
    "\n",
    "#Add network graph to the plot\n",
    "plot.renderers.append(network_graph)\n",
    "\n",
    "#Add Labels\n",
    "x, y = zip(*network_graph.layout_provider.graph_layout.values())\n",
    "node_labels = list(G.nodes())\n",
    "source = ColumnDataSource({'x': x, 'y': y, 'Source': [node_labels[i] for i in range(len(x))]})\n",
    "labels = LabelSet(x='x', y='y', text='Source', source=source, background_fill_color='white', text_font_size='10px', background_fill_alpha=.7)\n",
    "plot.renderers.append(labels)\n",
    "\n",
    "show(plot)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
